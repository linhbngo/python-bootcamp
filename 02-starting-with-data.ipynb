{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Starting With Data\n",
    "\n",
    "### Questions:\n",
    "    - \"How can I import data in Python?\"\n",
    "    - \"What is Pandas?\"\n",
    "    - \"Why should I use Pandas to work with data?\"\n",
    "### Objectives:\n",
    "    - \"Navigate the workshop directory and download a dataset.\"\n",
    "    - \"Explain what a library is and what libraries are used for.\"\n",
    "    - \"Describe what the Python Data Analysis Library (Pandas) is.\"\n",
    "    - \"Load the Python Data Analysis Library (Pandas).\"\n",
    "    - \"Use `read_csv` to read tabular data into Python.\"\n",
    "    - \"Describe what a DataFrame is in Python.\"\n",
    "    - \"Access and summarize data stored in a DataFrame.\"\n",
    "    - \"Define indexing as it relates to data structures.\"\n",
    "    - \"Perform basic mathematical operations and summary statistics on data in a Pandas DataFrame.\"\n",
    "    - \"Create simple plots.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Working With Pandas DataFrames in Python\n",
    "\n",
    "We can automate the process of performing data manipulations in Python. It's efficient to spend time\n",
    "building the code to perform these tasks because once it's built, we can use it\n",
    "over and over on different datasets that use a similar format. This makes our\n",
    "methods easily reproducible. We can also easily share our code with colleagues\n",
    "and they can replicate the same analysis.\n",
    "\n",
    "### Our Data\n",
    "\n",
    "For this lesson, we will be using the Portal Teaching data, a subset of the data\n",
    "from Ernst et al\n",
    "[Long-term monitoring and experimental manipulation of a Chihuahuan Desert ecosystem near Portal, Arizona, USA](http://www.esapubs.org/archive/ecol/E090/118/default.htm)\n",
    "\n",
    "We will be using files from the [Portal Project Teaching Database](https://figshare.com/articles/Portal_Project_Teaching_Database/1314459).\n",
    "This section will use the `surveys.csv` file that can be downloaded here:\n",
    "[https://ndownloader.figshare.com/files/2292172](https://ndownloader.figshare.com/files/2292172)\n",
    "\n",
    "We are studying the species and weight of animals caught in sites in our study\n",
    "area. The dataset is stored as a `.csv` file: each row holds information for a\n",
    "single animal, and the columns represent:\n",
    "\n",
    "| Column           | Description                        |\n",
    "|------------------|------------------------------------|\n",
    "| record_id        | Unique id for the observation      |\n",
    "| month            | month of observation               |\n",
    "| day              | day of observation                 |\n",
    "| year             | year of observation                |\n",
    "| plot_id          | ID of a particular site            |\n",
    "| species_id       | 2-letter code                      |\n",
    "| sex              | sex of animal (\"M\", \"F\")           |\n",
    "| hindfoot_length  | length of the hindfoot in mm       |\n",
    "| weight           | weight of the animal in grams      |\n",
    "\n",
    "\n",
    "The first few rows of our first file look like this:\n",
    "\n",
    "~~~\n",
    "record_id,month,day,year,plot_id,species_id,sex,hindfoot_length,weight\n",
    "1,7,16,1977,2,NL,M,32,\n",
    "2,7,16,1977,3,NL,M,33,\n",
    "3,7,16,1977,2,DM,F,37,\n",
    "4,7,16,1977,7,DM,M,36,\n",
    "5,7,16,1977,3,DM,M,35,\n",
    "6,7,16,1977,1,PF,M,14,\n",
    "7,7,16,1977,2,PE,F,,\n",
    "8,7,16,1977,1,DM,M,37,\n",
    "9,7,16,1977,1,DM,F,34,\n",
    "~~~\n",
    "\n",
    "---\n",
    "\n",
    "## About Libraries\n",
    "A library in Python contains a set of tools (called functions) that perform\n",
    "tasks on our data. Importing a library is like getting a piece of lab equipment\n",
    "out of a storage locker and setting it up on the bench for use in a project.\n",
    "Once a library is set up, it can be used or called to perform many tasks.\n",
    "\n",
    "## Pandas in Python\n",
    "One of the best options for working with tabular data in Python is to use the\n",
    "[Python Data Analysis Library](http://pandas.pydata.org/) (a.k.a. Pandas). The\n",
    "Pandas library provides data structures, produces high quality plots with\n",
    "[matplotlib](http://matplotlib.org/) and integrates nicely with other libraries\n",
    "that use [NumPy](http://www.numpy.org/) (which is another Python library) arrays.\n",
    "\n",
    "Python doesn't load all of the libraries available to it by default. We have to\n",
    "add an `import` statement to our code in order to use library functions. To import\n",
    "a library, we use the syntax `import libraryName`. If we want to give the\n",
    "library a nickname to shorten the command, we can add `as nickNameHere`.  An\n",
    "example of importing the pandas library using the common nickname `pd` is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Each time we call a function that's in a library, we use the syntax\n",
    "`LibraryName.FunctionName`. Adding the library name with a `.` before the\n",
    "function name tells Python where to find the function. In the example above, we\n",
    "have imported Pandas as `pd`. This means we don't have to type out `pandas` each\n",
    "time we call a Pandas function.\n",
    "\n",
    "\n",
    "# Reading CSV Data Using Pandas\n",
    "\n",
    "We will begin by locating and reading our survey data which are in CSV format. CSV stands for Comma-Separated Values and is a common way store formatted data. Other symbols may also be used, so you might see tab-separated, colon-separated or space separated files. It is quite easy to replace one separator with another, to match your application. The first line in the file often has headers to explain what is in each column. CSV (and other separators) make it easy to share data, and can be imported and exported from many applications, including Microsoft Excel. For more details on CSV files, see the [Data Organisation in Spreadsheets](http://www.datacarpentry.org/spreadsheet-ecology-lesson/05-exporting-data/) lesson.\n",
    "We can use Pandas' `read_csv` function to pull the file directly into a\n",
    "[DataFrame](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe).\n",
    "\n",
    "## So What's a DataFrame?\n",
    "\n",
    "A DataFrame is a 2-dimensional data structure that can store data of different\n",
    "types (including characters, integers, floating point values, factors and more)\n",
    "in columns. It is similar to a spreadsheet or an SQL table or the `data.frame` in\n",
    "R. A DataFrame always has an index (0-based). An index refers to the position of\n",
    "an element in the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note that pd.read_csv is used because we imported pandas as pd\n",
    "pd.read_csv(\"data/surveys.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can see that there were 35,549 rows parsed. Each row has 9\n",
    "columns. The first column is the index of the DataFrame. The index is used to\n",
    "identify the position of the data, but it is not an actual column of the DataFrame.\n",
    "It looks like  the `read_csv` function in Pandas  read our file properly. However,\n",
    "we haven't saved any data to memory so we can work with it. We need to assign the\n",
    "DataFrame to a variable. Remember that a variable is a name for a value, such as `x`,\n",
    "or  `data`. We can create a new  object with a variable name by assigning a value to it using `=`.\n",
    "\n",
    "Let's call the imported survey data `surveys_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df = pd.read_csv(\"data/surveys.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notice when you assign the imported DataFrame to a variable, Python does not\n",
    "produce any output on the screen. We can view the value of the `surveys_df`\n",
    "object by typing its name into the Python command prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "surveys_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Selecting just a few rows, so it is\n",
    "easier to fit on one window, you can see that pandas has neatly formatted the data to fit\n",
    "our screen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.head() # The head() method displays the first several lines of a file. It\n",
    "                  # is discussed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exploring Our Species Survey Data\n",
    "\n",
    "Again, we can use the `type` function to see what kind of thing `surveys_df` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(surveys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As expected, it's a DataFrame (or, to use the full name that Python uses to refer\n",
    "to it internally, a `pandas.core.frame.DataFrame`).\n",
    "\n",
    "What kind of things does `surveys_df` contain? DataFrames have an attribute\n",
    "called `dtypes` that answers this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "All the values in a column have the same type. For example, months have type\n",
    "`int64`, which is a kind of integer. Cells in the month column cannot have\n",
    "fractional values, but the weight and hindfoot_length columns can, because they\n",
    "have type `float64`. The `object` type doesn't have a very helpful name, but in\n",
    "this case it represents strings (such as 'M' and 'F' in the case of sex).\n",
    "\n",
    "We'll talk a bit more about what the different formats mean in a different lesson.\n",
    "\n",
    "### Useful Ways to View DataFrame objects in Python\n",
    "\n",
    "There are many ways to summarize and access the data stored in DataFrames,\n",
    "using attributes and methods provided by the DataFrame object.\n",
    "\n",
    "To access an attribute, use the DataFrame object name followed by the attribute\n",
    "name `df_object.attribute`. Using the DataFrame `surveys_df` and attribute\n",
    "`columns`, an index of all the column names in the DataFrame can be accessed\n",
    "with `surveys_df.columns`.\n",
    "\n",
    "Methods are called in a similar fashion using the syntax `df_object.method()`.\n",
    "As an example, `surveys_df.head()` gets the first few rows in the DataFrame\n",
    "`surveys_df` using **the `head()` method**. With a method, we can supply extra\n",
    "information in the parens to control behaviour.\n",
    "\n",
    "Let's look at the data using these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Challenge - DataFrames\n",
    "\n",
    "Using our DataFrame `surveys_df`, try out the attributes & methods below to see\n",
    "what they return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. `surveys_df.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2. `surveys_df.shape` Take note of the output of `shape` - what format does it\n",
    "    return the shape of the DataFrame in?\n",
    "\n",
    "    HINT: [More on tuples, here](https://docs.python.org/3/tutorial/datastructures.html#tuples-and-sequences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3. `surveys_df.head()` Also, what does `surveys_df.head(15)` do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "4. `surveys_df.tail()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Calculating Statistics From Data In A Pandas DataFrame\n",
    "\n",
    "We've read our data into Python. Next, let's perform some quick summary\n",
    "statistics to learn more about the data that we're working with. We might want\n",
    "to know how many animals were collected in each site, or how many of each\n",
    "species were caught. We can perform summary stats quickly using groups. But\n",
    "first we need to figure out what we want to group by.\n",
    "\n",
    "Let's begin by exploring our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the column names\n",
    "surveys_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's get a list of all the species. The `pd.unique` function tells us all of\n",
    "the unique values in the `species_id` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(surveys_df['species_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Challenge - Statistics\n",
    "\n",
    "1. Create a list of unique site ID's (\"plot_id\") found in the surveys data. Call it\n",
    "  `site_names`. How many unique sites are there in the data? How many unique\n",
    "  species are in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2. What is the difference between `len(site_names)` and `surveys_df['plot_id'].nunique()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Groups in Pandas\n",
    "\n",
    "We often want to calculate summary statistics grouped by subsets or attributes\n",
    "within fields of our data. For example, we might want to calculate the average\n",
    "weight of all individuals per site.\n",
    "\n",
    "We can calculate basic statistics for all records in a single column using the\n",
    "syntax below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df['weight'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can also extract one specific metric if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df['weight'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df['weight'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df['weight'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df['weight'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df['weight'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "But if we want to summarize by one or more variables, for example sex, we can\n",
    "use **Pandas' `.groupby` method**. Once we've created a groupby DataFrame, we\n",
    "can quickly calculate summary statistics by a group of our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by sex\n",
    "grouped_data = surveys_df.groupby('sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The **pandas function `describe`** will return descriptive stats including: mean,\n",
    "median, max, min, std and count for a particular column in the data. Pandas'\n",
    "`describe` function will only return summary values for columns containing\n",
    "numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for all numeric columns by sex\n",
    "grouped_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the mean for each numeric column by sex\n",
    "grouped_data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The `groupby` command is powerful in that it allows us to quickly generate\n",
    "summary stats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Challenge - Summary Data\n",
    "\n",
    "1. How many recorded individuals are female `F` and how many male `M`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2. What happens when you group by two columns using the following syntax and\n",
    "    then grab mean values:\n",
    "   - `grouped_data2 = surveys_df.groupby(['plot_id','sex'])`\n",
    "   - `grouped_data2.mean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3. Summarize weight values for each site in your data. HINT: you can use the\n",
    "   following syntax to only create summary statistics for one column in your data\n",
    "   `by_site['weight'].describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Quickly Creating Summary Counts in Pandas\n",
    "\n",
    "Let's next count the number of samples for each species. We can do this in a few\n",
    "ways, but we'll use `groupby` combined with **a `count()` method**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count the number of samples by species\n",
    "species_counts = surveys_df.groupby('species_id')['record_id'].count()\n",
    "print(species_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Or, we can also count just the rows that have the species \"DO\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.groupby('species_id')['record_id'].count()['DO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Basic Math Functions\n",
    "\n",
    "If we wanted to, we could perform math on an entire column of our data. For\n",
    "example let's multiply all weight values by 2. A more practical use of this might\n",
    "be to normalize the data according to a mean, area, or some other value\n",
    "calculated from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply all weight values by 2\n",
    "surveys_df['weight']*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Quick & Easy Plotting Data Using Pandas\n",
    "\n",
    "We can plot our summary stats using Pandas, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure figures appear inline in Ipython Notebook\n",
    "%matplotlib inline\n",
    "# Create a quick bar chart\n",
    "species_counts.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can also look at how many animals were captured in each site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = surveys_df.groupby('plot_id')['record_id'].nunique()\n",
    "# Let's plot that too\n",
    "total_count.plot(kind='bar');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

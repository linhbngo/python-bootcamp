{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "## Data Types and Formats\n\n### Questions:\n  - \"What types of data can be contained in a DataFrame?\"\n  - \"Why is the data type important?\"\n### Objectives:\n    - \"Describe how information is stored in a Python DataFrame.\"\n    - \"Define the two main types of data in Python: text and numerics.\"\n    - \"Examine the structure of a DataFrame.\"\n    - \"Modify the format of values in a DataFrame.\"\n    - \"Describe how data types impact operations.\"\n    - \"Define, manipulate, and interconvert integers and floats in Python.\"\n    - \"Analyze datasets having missing/null values (NaN values).\"\n    - \"Write manipulated data to a file.\"\n### Keypoints:\n    - \"Pandas uses other names for data types than Python, for example: `object` for textual data.\"\n    - \"A column in a DataFrame can only have one data type.\"\n    - \"The data type in a DataFrameâ€™s single column can be checked using `dtype`.\"\n    - \"Make conscious decisions about how to manage missing data.\"\n    - \"A DataFrame can be saved to a CSV file using the `to_csv` function.\"\n---\n\nThe format of individual columns and rows will impact analysis performed on a\ndataset read into python. For example, you can't perform mathematical\ncalculations on a string (text formatted data). This might seem obvious,\nhowever sometimes numeric values are read into Python as strings. In this\nsituation, when you then try to perform calculations on the string-formatted\nnumeric data, you get an error.\n\nIn this lesson we will review ways to explore and better understand the\nstructure and format of our data.\n\n### Types of Data\n\nHow information is stored in a\nDataFrame or a Python object affects what we can do with it and the outputs of\ncalculations as well. There are two main types of data that we're explore in\nthis lesson: numeric and text data types.\n\n### Numeric Data Types\n\nNumeric data types include integers and floats. A **floating point** (known as a\nfloat) number has decimal points even if that decimal point value is 0. For\nexample: 1.13, 2.0, 1234.345. If we have a column that contains both integers and\nfloating point numbers, Pandas will assign the entire column to the float data\ntype so the decimal points are not lost.\n\nAn **integer** will never have a decimal point. Thus if we wanted to store 1.13 as\nan integer it would be stored as 1. Similarly, 1234.345 would be stored as 1234. You\nwill often see the data type `Int64` in Python which stands for 64 bit integer. The 64\nsimply refers to the memory allocated to store data in each cell which effectively\nrelates to how many digits it can store in each \"cell\". Allocating space ahead of time\nallows computers to optimize storage and processing efficiency.\n\n### Text Data Type\n\nText data type is known as Strings in Python, or Objects in Pandas. Strings can\ncontain numbers and / or characters. For example, a string might be a word, a\nsentence, or several sentences. A Pandas object might also be a plot name like\n'plot1'. A string can also contain or consist of numbers. For instance, '1234'\ncould be stored as a string. As could '10.23'. However **strings that contain\nnumbers can not be used for mathematical operations**!\n\nPandas and base Python use slightly different names for data types. More on this\nis in the table below:\n\n| Pandas Type | Native Python Type | Description |\n|-------------|--------------------|-------------|\n| object | string | The most general dtype. Will be assigned to your column if column has mixed types (numbers and strings). |\n| int64  | int | Numeric characters. 64 refers to the memory allocated to hold this character. |\n| float64 | float | Numeric characters with decimals. If a column contains numbers and NaNs (see below), pandas will default to float64, in case your missing value has a decimal. |\n| datetime64, timedelta[ns] | N/A (but see the [datetime] module in Python's standard library) | Values meant to hold time data. Look into these for time series experiments. |\n\n[datetime]: http://doc.python.org/2/library/datetime.html\n\n\n### Checking the format of our data\n\nNow that we're armed with a basic understanding of numeric and text data\ntypes, let's explore the format of our survey data. We'll be working with the\nsame `surveys.csv` dataset that we've used in previous lessons."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\n# Note that pd.read_csv is used because we imported pandas as pd\nsurveys_df = pd.read_csv(\"data/surveys.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Remember that we can check the type of an object like this:\ntype(surveys_df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "Next, let's look at the structure of our surveys data. In pandas, we can check\nthe type of one column in a DataFrame using the syntax\n`dataFrameName[column_name].dtype`:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "surveys_df['sex'].dtype",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "A type 'O' just stands for \"object\" which in Pandas' world is a string\n(text)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "surveys_df['record_id'].dtype",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "The type `int64` tells us that Python is storing each value within this column\nas a 64 bit integer. We can use the `dat.dtypes` command to view the data type\nfor each column in a DataFrame (all at once)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "surveys_df.dtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "Note that most of the columns in our Survey data are of type `int64`. This means\nthat they are 64 bit integers. But the weight column is a floating point value\nwhich means it contains decimals. The `species_id` and `sex` columns are objects which\nmeans they contain strings.\n\n## Working With Integers and Floats\n\nSo we've learned that computers store numbers in one of two ways: as integers or\nas floating-point numbers (or floats). Integers are the numbers we usually count\nwith. Floats have fractional parts (decimal places).  Let's next consider how\nthe data type can impact mathematical operations on our data. Addition,\nsubtraction, division and multiplication work on floats and integers as we'd expect."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(5+5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(24-4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "If we divide one integer by another, we get a float.\nThe result on Python 3 is different than in Python 2, where the result is an\ninteger (integer division)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(5/9)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(10/3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "We can also convert a floating point number to an integer or an integer to\nfloating point number. Notice that Python by default rounds down when it\nconverts from floating point to integer."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Convert a to an integer\na = 7.83\nint(a)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Convert b to a float\nb = 7\nfloat(b)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "### Working With Our Survey Data\n\nGetting back to our data, we can modify the format of values within our data, if\nwe want. For instance, we could convert the `record_id` field to floating point\nvalues."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Convert the record_id field from an integer to a float\nsurveys_df['record_id'] = surveys_df['record_id'].astype('float64')\nsurveys_df['record_id'].dtype",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "### Challenge - Changing Types\n\nTry converting the column `plot_id` to floats using `surveys_df.plot_id.astype(\"float\")`\n \n\nNext try converting `weight` to an integer. What goes wrong here? What is Pandas telling you?\n We will talk about some solutions to this later."
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "### Missing Data Values - NaN\n\nWhat happened in the last challenge activity? Notice that this throws a value error:\n`ValueError: Cannot convert NA to integer`. If we look at the `weight` column in the surveys\ndata we notice that there are NaN (**N**ot **a** **N**umber) values. **NaN** values are undefined\nvalues that cannot be represented mathematically. Pandas, for example, will read\nan empty cell in a CSV or Excel sheet as a NaN. NaNs have some desirable properties: if we\nwere to average the `weight` column without replacing our NaNs, Python would know to skip\nover those cells."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "surveys_df['weight'].mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "Dealing with missing data values is always a challenge. It's sometimes hard to\nknow why values are missing - was it because of a data entry error? Or data that\nsomeone was unable to collect? Should the value be 0? We need to know how\nmissing values are represented in the dataset in order to make good decisions.\nIf we're lucky, we have some metadata that will tell us more about how null\nvalues were handled.\n\nFor instance, in some disciplines, like Remote Sensing, missing data values are\noften defined as -9999. Having a bunch of -9999 values in your data could really\nalter numeric calculations. Often in spreadsheets, cells are left empty where no\ndata are available. Pandas will, by default, replace those missing values with\nNaN. However it is good practice to get in the habit of intentionally marking\ncells that have no data, with a no data value! That way there are no questions\nin the future when you (or someone else) explores your data.\n\n### Where Are the NaN's?\n\nLet's explore the NaN values in our data a bit further. Using the tools we\nlearned in lesson 02, we can figure out how many rows contain NaN values for\nweight. We can also create a new subset from our data that only contains rows\nwith weight values > 0 (i.e., select meaningful weight values):"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(surveys_df[pd.isnull(surveys_df.weight)])\n# How many rows have weight values?\nlen(surveys_df[surveys_df.weight> 0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "We can replace all NaN values with zeroes using the `.fillna()` method (after\nmaking a copy of the data so we don't lose our work):"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df1 = surveys_df.copy()\n# Fill all NaN values with 0\ndf1['weight'] = df1['weight'].fillna(0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "However NaN and 0 yield different analysis results. The mean value when NaN\nvalues are replaced with 0 is different from when NaN values are simply thrown\nout or ignored."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df1['weight'].mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "We can fill NaN values with any value that we chose. The code below fills all\nNaN values with a mean for all weight values.\n\n\n `df1['weight'] = surveys_df['weight'].fillna(surveys_df['weight'].mean())`\n\n\n\nWe could also chose to create a subset of our data, only keeping rows that do\nnot contain NaN values.\n\nThe point is to make conscious decisions about how to manage missing data. This\nis where we think about how our data will be used and how these values will\nimpact the scientific conclusions made from the data.\n\nPython gives us all of the tools that we need to account for these issues. We\njust need to be cautious about how the decisions that we make impact scientific\nresults."
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "### Writing Out Data to CSV\n\nWe've learned about using manipulating data to get desired outputs. But we've also discussed\nkeeping data that has been manipulated separate from our raw data. Something we might be interested\nin doing is working with only the columns that have full data. First, let's reload the data so\nwe're not mixing up all of our previous manipulations."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "surveys_df = pd.read_csv(\"data/surveys.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "Next, let's drop all the rows that contain missing values. We will use the command `dropna`.\nBy default, dropna removes columns that contain missing data for even just one row."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_na = surveys_df.dropna()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "If you now type `df_na`, you should observe that the resulting DataFrame has 30676 rows\nand 9 columns, much smaller than the 35549 row original.\n\nWe can now use the `to_csv` command to do export a DataFrame in CSV format. Note that the code\nbelow will by default save the data into the current working directory. We can\nsave it to a different folder by adding the foldername and a slash before the filename:\n`df.to_csv('foldername/out.csv')`. We use 'index=False' so that\npandas doesn't include the index number for each line."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Write DataFrame to CSV\ndf_na.to_csv('data/surveys_complete.csv', index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}